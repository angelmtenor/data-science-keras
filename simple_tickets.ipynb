{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Tickets prediction with DNN\n",
    "\n",
    "**Predicting the number of tickets requested by different clients**\n",
    "\n",
    "**Supervised Learning. Regression**\n",
    "\n",
    "\n",
    "Data taken from [Udacity's problem solving with advanced analytics](https://www.udacity.com/course/problem-solving-with-advanced-analytics--ud976)\n",
    "\n",
    "Here a neural network is effectively appllied in a simple problem usually solved with linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import helper\n",
    "import keras\n",
    "\n",
    "helper.info_gpu()\n",
    "helper.reproducible(seed=9)  # setup reproducible results from run to run using Keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/simple_tickets_data.csv\"\n",
    "target = [\"Average Number of Tickets\"]\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"rows: {} \\ncolumns: {} \\ntarget: {}\".format(*df.shape, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.missing(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Client ID\", axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [\"Number of Employees\", \"Value of Contract\", \"Average Number of Tickets\"]\n",
    "\n",
    "df = helper.classify_data(df, target, numerical)\n",
    "\n",
    "pd.DataFrame(dict(df.dtypes), index=[\"Type\"])[df.columns].head()  # show data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.show_categorical(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target vs Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.show_target_vs_categorical(df, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.show_numerical(df, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target vs Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.show_target_vs_numerical(df, target, point_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target vs All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(\n",
    "    df,\n",
    "    y_vars=target,\n",
    "    x_vars=[\"Number of Employees\", \"Value of Contract\"],\n",
    "    size=7,\n",
    "    hue=\"Industry\",\n",
    "    aspect=1.5,\n",
    ")\n",
    "g.map(sns.regplot).add_legend();\n",
    "\n",
    "# sns.pairplot(df, hue = 'Industry', vars=['Number of Employees', 'Value of Contract'] +\n",
    "#             targets, size = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These figures suggest that a simple linear model could be used to make accurate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between numerical features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.show_correlation(df, target, figsize=(7, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist = []  # features to drop\n",
    "\n",
    "# For the model 'data' instead of 'df'\n",
    "data = df.copy()\n",
    "data.drop(droplist, axis=\"columns\", inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical variables\n",
    "Shift and scale numerical variables to a standard normal distribution. The scaling factors are saved to be used for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, scale_param = helper.scale(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy features\n",
    "Replace categorical features (no target) with dummy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, dict_dummies = helper.replace_by_dummies(data, target)\n",
    "\n",
    "model_features = [f for f in data if f not in target]  # sorted neural network inputs\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test set\n",
    "\n",
    "Data leakage: Test set hidden when training the model, but seen when preprocessing the dataset\n",
    "\n",
    "No validation set will be used here (300 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_state = 0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(data, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Separate the data into features and target (x=features, y=target)\n",
    "x_train, y_train = train.drop(target, axis=1).values, train[target].values\n",
    "x_test, y_test = test.drop(target, axis=1).values, test[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the output not needed for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train size \\t X:{} \\t Y:{}\".format(x_train.shape, y_train.shape))\n",
    "print(\"test size  \\t X:{} \\t Y:{} \".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network for Regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n",
    "\n",
    "def build_nn(input_size, output_size, summary=False):\n",
    "\n",
    "    input_nodes = input_size\n",
    "    weights = keras.initializers.RandomNormal(stddev=0.001)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            input_nodes,\n",
    "            input_dim=input_size,\n",
    "            activation=\"tanh\",\n",
    "            kernel_initializer=weights,\n",
    "            bias_initializer=weights,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(Dense(1, activation=None, kernel_initializer=weights, bias_initializer=weights))\n",
    "\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "    if summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "model_path = os.path.join(\"models\", \"simple_tickets.h5\")\n",
    "\n",
    "\n",
    "def train_nn(model, x_train, y_train, validation_data=None, path=False, show=True):\n",
    "    \"\"\"\n",
    "    Train the neural network model. If no validation_datais provided, a split for validation\n",
    "    will be used\n",
    "    \"\"\"\n",
    "\n",
    "    if show:\n",
    "        print(\"Training ....\")\n",
    "\n",
    "    # callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0)]\n",
    "    t0 = time()\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=30,\n",
    "        batch_size=16,\n",
    "        validation_split=0,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=None,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        print(\"time: \\t {:.1f} s\".format(time() - t0))\n",
    "        helper.show_training(history)\n",
    "\n",
    "    if path:\n",
    "        model.save(path)\n",
    "        print(\"\\nModel saved at\", path)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "model = None\n",
    "model = build_nn(x_train.shape[1], y_train.shape[1], summary=False)\n",
    "train_nn(model, x_train, y_train, validation_data=None, path=model_path)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "ypred_train = model.predict(x_train)\n",
    "# ypred_val = model.predict(x_val)\n",
    "print(\"Training   R2-score: \\t{:.3f}\".format(r2_score(y_train, ypred_train)))\n",
    "# print('Validation R2-score: \\t{:.3f}'.format(r2_score(y_val, ypred_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(model_path)\n",
    "# print(\"Model loaded:\", model_path)\n",
    "\n",
    "\n",
    "def evaluate_nn(model, x_test, y_test):\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"\\nTest loss:\\t\\t{:.4f}\".format(score))\n",
    "\n",
    "    ypred_test = model.predict(x_test)\n",
    "    print(\"\\nTest R2-score: \\t\\t{:.3f}\".format(r2_score(y_test, ypred_test)))\n",
    "\n",
    "\n",
    "evaluate_nn(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nn(model, x_test, target):\n",
    "    \"\"\"Return a dataframe with actual and predicted targets in original scale\"\"\"\n",
    "\n",
    "    for t in target:\n",
    "        pred = model.predict(x_test, verbose=0)\n",
    "        restore_pred = pred * scale_param[t][1] + scale_param[t][0]\n",
    "        restore_pred = restore_pred.round()\n",
    "\n",
    "        restore_y = y_test * scale_param[t][1] + scale_param[t][0]\n",
    "        restore_y = restore_y.round()\n",
    "\n",
    "        pred_label = \"Predicted_\" + t\n",
    "        error_label = t + \" error (%)\"\n",
    "\n",
    "        pred_df = pd.DataFrame({t: np.squeeze(restore_y), pred_label: np.squeeze(restore_pred)})\n",
    "\n",
    "        pred_df[error_label] = ((pred_df[pred_label] - pred_df[t]) * 100 / pred_df[t]).round(1)\n",
    "\n",
    "        print(t, \". Prediction error:\")\n",
    "        print(\"Mean: \\t {:.2f}%\".format(pred_df[error_label].mean()))\n",
    "        print(\"Stddev:  {:.2f}%\".format(pred_df[error_label].std()))\n",
    "        sns.distplot(pred_df[error_label])\n",
    "        plt.xlim(xmin=-600, xmax=600)\n",
    "\n",
    "    return pred_df\n",
    "\n",
    "\n",
    "pred_df = predict_nn(model, x_test, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction error (%) can be especially high when the number of tickets is low. The absolute error could be a better indicator here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "pred = reg.predict(x_test)\n",
    "\n",
    "t = target[0]\n",
    "restore_pred = pred * scale_param[t][1] + scale_param[t][0]\n",
    "restore_pred = restore_pred.round()\n",
    "\n",
    "restore_y = y_test * scale_param[t][1] + scale_param[t][0]\n",
    "restore_y = restore_y.round()\n",
    "\n",
    "pred_label = \"Predicted_\" + t\n",
    "error_label = t + \" error (%)\"\n",
    "\n",
    "pred_df = pd.DataFrame({t: np.squeeze(restore_y), pred_label: np.squeeze(restore_pred)})\n",
    "\n",
    "pred_df[error_label] = ((pred_df[pred_label] - pred_df[t]) * 100 / pred_df[t]).round(1)\n",
    "\n",
    "print(t, \". Prediction error:\")\n",
    "print(\"Mean: \\t {:.2f}%\".format(pred_df[error_label].mean()))\n",
    "print(\"Stddev:  {:.2f}%\".format(pred_df[error_label].std()))\n",
    "sns.distplot(pred_df[error_label])\n",
    "plt.xlim(xmin=-600, xmax=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean and standard deviation of the error is higher with the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with classical ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.ml_regression(x_train, y_train[:, 0], x_test, y_test[:, 0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
