{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Network Analysis. Predict salary and new connections \n",
    "\n",
    "**Predicting missing salaries and new email connections from a company's email network**\n",
    "\n",
    "**Network Analysis. Supervised Learning. Regression (Salary prediction) and Classification (New connections prediction)**\n",
    "\n",
    "\n",
    "Data from [Applied Social Network Analysis in Python | Coursera](https://www.coursera.org/learn/python-social-network-analysis/):\n",
    "\n",
    "`net_emails.txt`: network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people. \n",
    "The network also contains the node attributes Department (*name*) and ManagementSalary (1 = Receiving a management salary)\n",
    "\n",
    "`net_future_connections.csv`: future conections of pair of nodes currently unconnected (1 = an edge between those two nodes will exist in the future)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import helper_ds\n",
    "\n",
    "helper_ds.set_parent_execution_path()\n",
    "helper_ds.info_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Salary Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.read_gpickle(\"data/net_emails.txt\")\n",
    "\n",
    "print(nx.info(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract node attributes and features to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.nodes(data=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with node attributes\n",
    "df = pd.DataFrame(index=graph.nodes())  # df: complete df\n",
    "attributes = [k for k in graph.nodes(data=True)[0][1]]\n",
    "for a in attributes:\n",
    "    df[a] = pd.Series(nx.get_node_attributes(graph, a))\n",
    "\n",
    "# node features\n",
    "df[\"clustering\"] = pd.Series(nx.clustering(graph))\n",
    "df[\"degree\"] = pd.Series(graph.degree())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the target and separate the prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\"ManagementSalary\"]\n",
    "features = [col for col in df if col not in target]\n",
    "\n",
    "print(df[target].squeeze().value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows_original = df.shape[0]\n",
    "\n",
    "df_pred = df[df[\"ManagementSalary\"].isnull()]\n",
    "df = df[(df[\"ManagementSalary\"] == 0) | (df[\"ManagementSalary\"] == 1)]\n",
    "\n",
    "assert df.shape[0], df_pred.shape[0] == n_rows_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df[target], random_state=0)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_pred`: prediction set (no labels) <br>\n",
    "`df_train`: training_set  <br>\n",
    "`df_test`: test_set  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify features\n",
    "Change categorical variables as dtype 'categorical' and sort columns: numerical + categorical + target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_ds\n",
    "\n",
    "cat = [\"Department\", \"ManagementSalary\"]\n",
    "num = [\"clustering\", \"degree\"]\n",
    "\n",
    "df_train = helper_ds.sort_columns_by_type(df_train, target, categorical=cat)\n",
    "\n",
    "pd.DataFrame(dict(df_train.dtypes), index=[\"Type\"])[df_train.columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, dict_categories = helper_ds.remove_categories(df_train, target, ratio=0.01, show=True,\n",
    "#                                                      dict_categories=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num].describe(percentiles=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.show_numerical(df_train[num], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.show_target_vs_numerical(df_train, target, jitter=0.2, fit_reg=False, point_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.correlation(df_train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[cat].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.show_categorical(df_train[cat], target, sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.show_target_vs_categorical(df_train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_missing = helper_ds.missing(df_train, limit=0.4)\n",
    "# helper_ds.fill_simple(df_train, target, missing_categorical=999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df_train.copy()  # checkpoint\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = copy_df.copy()  # Restore checkpoint\n",
    "data = df_train.copy()\n",
    "# from now on use data instead of df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, scale_param = helper_ds.scale(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dummy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features only; target encoded later\n",
    "data, dict_dummies = helper_ds.replace_by_dummies(data, target)\n",
    "\n",
    "# save features order for tests and predictions\n",
    "model_features = [f for f in data if f not in target]\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_split(data, val_size=0.15):\n",
    "\n",
    "    train, val = train_test_split(data, test_size=val_size, random_state=0, shuffle=True, stratify=data[target])\n",
    "\n",
    "    # Separate the data into features and target (x=features, y=target)\n",
    "    x_train, y_train = train.drop(target, axis=1).values, train[target].values\n",
    "    x_val, y_val = val.drop(target, axis=1).values, val[target].values\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "x_train, y_train, x_val, y_val = validation_split(data, val_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "\n",
    "def one_hot_output(y_train, y_val):\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "    return y_train, y_val\n",
    "\n",
    "\n",
    "y_train, y_val = one_hot_output(y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train size \\t X:{} \\t Y:{}\".format(x_train.shape, y_train.shape))\n",
    "print(\"val size \\t X:{} \\t Y:{}\".format(x_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "def build_nn_binary_classification(input_size, output_size, summary=False):\n",
    "\n",
    "    input_nodes = input_size // 8\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_nodes, input_dim=input_size, kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "    model.add(Dense(output_size, activation=\"softmax\", kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    if summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "build_nn = build_nn_binary_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import time\n",
    "\n",
    "\n",
    "def train_nn(model, x_train, y_train, validation_data=None, path=False, show=True):\n",
    "    \"\"\"\n",
    "    Train the neural network model. If no validation_datais provided, a split for validation\n",
    "    will be used\n",
    "    \"\"\"\n",
    "\n",
    "    if show:\n",
    "        print(\"Training ....\")\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=0, verbose=0)]\n",
    "    t0 = time()\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "        verbose=0,\n",
    "        validation_data=validation_data,\n",
    "        # class_weight=cw, # worse results\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        print(\"time: \\t {:.1f} s\".format(time() - t0))\n",
    "        helper_ds.show_training(history)\n",
    "\n",
    "    if path:\n",
    "        model.save(path)\n",
    "        print(\"\\nModel saved at\", path)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "model = None\n",
    "model = build_nn_binary_classification(x_train.shape[1], y_train.shape[1], summary=True)\n",
    "train_nn(model, x_train, y_train, validation_data=(x_val, y_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = helper_ds.sort_columns_by_type(df_test, target, categorical=cat)\n",
    "data_test, _ = helper_ds.scale(data_test, scale_param)\n",
    "data_test, _ = helper_ds.replace_by_dummies(data_test, target, dict_dummies)\n",
    "data_test = data_test[model_features + target]  # sort columns to match training features order\n",
    "x_test, y_test = data_test.drop(target, axis=1).values, data_test[target].values\n",
    "y_test = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"\\nNeural Network Accuracy: {:.3f}\\n\".format(score[1]))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"Neural Network ROC AUC:  {:.3f} \\n\".format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3. Compare with non-neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:, 1]\n",
    "y_test = y_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import class_weight\n",
    "# y_plain = np.ravel(y_train)\n",
    "# cw = class_weight.compute_class_weight('balanced', np.unique(y_plain), y_plain)\n",
    "# cw = {idx : value for idx, value in enumerate(cw)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.ml_classification(x_train, y_train, x_test, y_test, cross_validation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Future Connection Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train, df_test, df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/net_future_connections.csv\", index_col=0, converters={0: eval})\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract edge-based attributes from the above graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Common Neighbors\"] = df.index.map(lambda city: len(list(nx.common_neighbors(graph, city[0], city[1]))))\n",
    "df[\"Jaccard Coefficient\"] = [i[2] for i in nx.jaccard_coefficient(graph, df.index)]\n",
    "df[\"ResourceWarningurce Allocation\"] = [i[2] for i in nx.resource_allocation_index(graph, df.index)]\n",
    "df[\"Adamic-Adar Index\"] = [i[2] for i in nx.adamic_adar_index(graph, df.index)]\n",
    "df[\"Preferential Attachment\"] = [i[2] for i in nx.preferential_attachment(graph, df.index)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the target and separate the prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [\"Future Connection\"]\n",
    "features = [col for col in df if col not in target]\n",
    "\n",
    "df[\"Future Connection\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows_original = df.shape[0]\n",
    "\n",
    "df_pred = df[df[\"Future Connection\"].isnull()]\n",
    "df = df[(df[\"Future Connection\"] == 0) | (df[\"Future Connection\"] == 1)]\n",
    "\n",
    "assert df.shape[0], df_pred.shape[0] == n_rows_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df[target], random_state=0)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_pred`: prediction set (no labels) <br>\n",
    "`df_train`: training_set  <br>\n",
    "`df_test`: test_set  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify features\n",
    "Change categorical variables as dtype 'categorical' and sort columns: numerical + categorical + target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_ds\n",
    "\n",
    "cat = [\"Future Connection\"]\n",
    "num = features  # all the features are numerical here\n",
    "\n",
    "df_train = helper_ds.sort_columns_by_type(df_train, target, categorical=cat)\n",
    "\n",
    "pd.DataFrame(dict(df_train.dtypes), index=[\"Type\"])[df_train.columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num].describe(percentiles=[0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.show_numerical(df_train, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.show_target_vs_numerical(df_train, target, jitter=0.2, fit_reg=False, point_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.correlation(df_train, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_missing = helper_ds.missing(df_train, limit=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df = df_train.copy()  # checkpoint\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = copy_df.copy()  # Restore checkpoint\n",
    "data = df_train.copy()\n",
    "# from now on use data instead of df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, scale_param = helper_ds.scale(data)\n",
    "\n",
    "model_features = [f for f in data if f not in target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_split(data, val_size=0.15):\n",
    "\n",
    "    train, val = train_test_split(data, test_size=val_size, random_state=0, shuffle=True, stratify=data[target])\n",
    "\n",
    "    # Separate the data into features and target (x=features, y=target)\n",
    "    x_train, y_train = train.drop(target, axis=1).values, train[target].values\n",
    "    x_val, y_val = val.drop(target, axis=1).values, val[target].values\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "\n",
    "x_train, y_train, x_val, y_val = validation_split(data, val_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "\n",
    "def one_hot_output(y_train, y_val):\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "    return y_train, y_val\n",
    "\n",
    "\n",
    "y_train, y_val = one_hot_output(y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train size \\t X:{} \\t Y:{}\".format(x_train.shape, y_train.shape))\n",
    "print(\"val size \\t X:{} \\t Y:{}\".format(x_val.shape, y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn_binary_classification(input_size, output_size, summary=False):\n",
    "\n",
    "    input_nodes = input_size\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            input_nodes,\n",
    "            input_dim=input_size,\n",
    "            kernel_regularizer=regularizers.l2(0.0001),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            output_size,\n",
    "            activation=\"softmax\",\n",
    "            kernel_regularizer=regularizers.l2(0.0001),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "    if summary:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "build_nn = build_nn_binary_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, x_train, y_train, validation_data=None, path=False, show=True):\n",
    "    \"\"\"\n",
    "    Train the neural network model. If no validation_data is provided, a split for validation\n",
    "    will be used\n",
    "    \"\"\"\n",
    "\n",
    "    if show:\n",
    "        print(\"Training ....\")\n",
    "\n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=0, verbose=0)]\n",
    "    t0 = time()\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "        batch_size=1024,\n",
    "        verbose=0,\n",
    "        validation_data=validation_data,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    if show:\n",
    "        print(\"time: \\t {:.1f} s\".format(time() - t0))\n",
    "        helper_ds.show_training(history)\n",
    "\n",
    "    if path:\n",
    "        model.save(path)\n",
    "        print(\"\\nModel saved at\", path)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "model = None\n",
    "model = build_nn_binary_classification(x_train.shape[1], y_train.shape[1], summary=True)\n",
    "train_nn(model, x_train, y_train, validation_data=(x_val, y_val));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = helper_ds.sort_columns_by_type(df_test, target, categorical=cat)\n",
    "data_test, _ = helper_ds.scale(data_test, scale_param)\n",
    "data_test = data_test[model_features + target]  # sort columns to match training features order\n",
    "x_test, y_test = data_test.drop(target, axis=1).values, data_test[target].values\n",
    "y_test = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"\\nNeural Network Accuracy: {:.3f}\\n\".format(score[1]))\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"Neural Network ROC AUC:  {:.3f} \\n\".format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B3. Compare with non-neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:, 1]\n",
    "y_test = y_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf=None\n",
    "# clf = RandomForestClassifier()\n",
    "# clf.fit(x_train, np.ravel(y_train))\n",
    "# print(\"\\nRandom Forest Accuracy: {:.3f}\\n\".format(clf.score(x_train, y_train)))\n",
    "# y_pred = clf.predict_proba(x_test)\n",
    "# print('Random Forest ROC_AUC: {:.3f}'.format(roc_auc_score(y_test, y_pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_ds.ml_classification(x_train, y_train, x_test, y_test, cross_validation=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
