{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spam detector\n",
                "\n",
                "**Predicting the probability that a given email is a spam email**\n",
                "\n",
                "**Natural Language Processing. Supervised Learning. Binary classification**\n",
                "\n",
                "Data from [Applied Text Mining in Python | Coursera](https://www.coursera.org/learn/python-text-mining/)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import helper_ml"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"data/spam.csv\")\n",
                "print(\"{} rows \\n{} columns\".format(*df.shape))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Explore and clean the target"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# print(df['target'].squeeze().value_counts(dropna=False))\n",
                "df[\"target\"] = np.where(df[\"target\"] == \"spam\", 1, 0)  # change target ('ham', 'spam') to (0,1)\n",
                "print(\"Ratio of email spam: {:.3f}\".format(np.mean(df[\"target\"])))\n",
                "df.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "####  Split data into training and test set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "df_train, df_test = train_test_split(df, test_size=0.3, stratify=df[\"target\"], random_state=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Transform data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import keras\n",
                "from keras.preprocessing.text import Tokenizer\n",
                "from keras.preprocessing.sequence import pad_sequences\n",
                "\n",
                "max_words = 1000\n",
                "max_length = 10\n",
                "\n",
                "x_train, y_train = df_train[\"text\"], df_train[\"target\"]\n",
                "x_test, y_test = df_test[\"text\"], df_test[\"target\"]\n",
                "\n",
                "tokenizer = Tokenizer(num_words=max_words)\n",
                "# non-alphanumeric characters could be important here (filters=''), but better results were\n",
                "#  obtained with default filters\n",
                "\n",
                "tokenizer.fit_on_texts(x_train)\n",
                "\n",
                "x_train = tokenizer.texts_to_sequences(x_train)\n",
                "x_test = tokenizer.texts_to_sequences(x_test)\n",
                "\n",
                "# padding\n",
                "x_train = pad_sequences(x_train, max_length)\n",
                "x_test = pad_sequences(x_test, max_length)\n",
                "\n",
                "# one-hot encoding the target\n",
                "num_classes = 2\n",
                "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
                "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
                "\n",
                "print(\"train size \\t X:{} \\t Y:{}\".format(x_train.shape, y_train.shape))\n",
                "print(\"test size  \\t X:{} \\t Y:{} \".format(x_test.shape, y_test.shape))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Neural Network"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from keras.models import Sequential\n",
                "from keras.layers import Dense, Dropout, Flatten\n",
                "from keras.layers.embeddings import Embedding\n",
                "\n",
                "model = Sequential()\n",
                "model.add(Embedding(max_words, 10, input_length=max_length))\n",
                "model.add(Flatten())\n",
                "model.add(Dense(10, activation='relu'))\n",
                "model.add(Dropout(0.25))\n",
                "model.add(Dense(num_classes, activation='softmax'))\n",
                "model.summary()\n",
                "\n",
                "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
                "\n",
                "print('Training ....')\n",
                "callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=0, verbose=1)]\n",
                "%time history = model.fit(x_train, y_train, batch_size=128, epochs=30, verbose=0, \\\n",
                "                          validation_split = 0.3, callbacks=callbacks)\n",
                "\n",
                "helper_ml.show_training(history)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Evaluate Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "score = model.evaluate(x_test, y_test, verbose=0)\n",
                "print(\"\\nTest Accuracy: {:.3f}\\n\".format(score[1]))\n",
                "\n",
                "y_pred = model.predict(x_test)\n",
                "\n",
                "from sklearn.metrics import roc_auc_score\n",
                "\n",
                "print(\"Neural Network ROC AUC: {:.3f} \\n\".format(roc_auc_score(y_test, y_pred)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Compare with classical vectorizer + Multinomial Naive Bayes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "\n",
                "x_train, y_train = df_train[\"text\"], df_train[\"target\"]\n",
                "x_test, y_test = df_test[\"text\"], df_test[\"target\"]\n",
                "\n",
                "vect = CountVectorizer().fit(x_train)\n",
                "\n",
                "x_train_vectorized = vect.transform(x_train)\n",
                "\n",
                "model = MultinomialNB(alpha=0.2).fit(x_train_vectorized, y_train)\n",
                "\n",
                "predictions = model.predict(vect.transform(x_test))\n",
                "\n",
                "print(\"\\nMultinomialNB ROC_AUC: {:.3f}\".format(roc_auc_score(y_test, predictions)))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
