{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test \n",
    "\n",
    "**Simple Supervised Learning. Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 500\n",
    "x = np.linspace(0, 200, data_size)\n",
    "\n",
    "y = np.array([-i * i + 1200 for i in np.linspace(-50, 50, num=data_size)])\n",
    "y = y + np.random.normal(0, 100, data_size)  # add noise\n",
    "\n",
    "df = pd.DataFrame({\"x\": x, \"y\": y})\n",
    "target = [\"y\"]\n",
    "\n",
    "print(\"rows: {} \\ncolumns: {} \\ntarget: {}\".format(*df.shape, target))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"x\", y=\"y\", figsize=(12, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between numerical features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.copy()\n",
    "\n",
    "# Standarize x & y\n",
    "scale = {}\n",
    "\n",
    "for col in data:\n",
    "    mean, std = data[col].mean(), data[col].std()\n",
    "    data[col] = (data[col] - mean) / std\n",
    "    scale[col] = [mean, std]\n",
    "\n",
    "test_size = 0\n",
    "\n",
    "train, test = train_test_split(data, test_size=test_size, random_state=9, shuffle=True)\n",
    "x_train, y_train = train.drop(target, axis=1).values, train[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "\n",
    "# weights = keras.initializers.RandomNormal(stddev=0.01)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, input_dim=1, activation=\"tanh\"))\n",
    "\n",
    "model.add(Dense(1, activation=None))\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, verbose=0)]\n",
    "t0 = time()\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_split=0.25,\n",
    "    callbacks=callbacks,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "print(\"time: \\t {:.1f} s\".format(time() - t0))\n",
    "\n",
    "hist = history.history\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(hist[\"loss\"], label=\"Training\")\n",
    "if \"val_loss\" in hist:\n",
    "    plt.plot(hist[\"val_loss\"], label=\"Validation\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data.drop(target, axis=1).values\n",
    "\n",
    "pred = model.predict(x_test, verbose=0)\n",
    "\n",
    "df_pred = data.copy()\n",
    "df_pred[\"y_pred\"] = pred\n",
    "\n",
    "ax = df_pred.plot.scatter(\"x\", \"y\", figsize=(12, 5), s=15, label=\"y\")\n",
    "df_pred.plot.scatter(\"x\", \"y_pred\", ax=ax, c=\"r\", s=15, label=\"y_pred\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with non-neural network models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import xgboost as xgb\n",
    "\n",
    "reg = None\n",
    "reg = xgb.XGBRegressor()\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "reg.fit(x_train, y_train[:, 0])\n",
    "train_time = time() - t0\n",
    "\n",
    "print(\"Training Time:  \\t {:.3f} s\".format(train_time))\n",
    "\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "df_pred2 = data.copy()\n",
    "df_pred2[\"y_pred\"] = y_pred\n",
    "\n",
    "ax = df_pred2.plot.scatter(\"x\", \"y\", figsize=(12, 5), s=15, label=\"y\")\n",
    "df_pred2.plot.scatter(\"x\", \"y_pred\", ax=ax, c=\"r\", s=15, label=\"y_pred\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector regression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "reg = None\n",
    "reg = SVR(C=1)\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "reg.fit(x_train, y_train[:, 0])\n",
    "\n",
    "print(\"Training Time:  \\t {:.3f} s\".format(time() - t0))\n",
    "\n",
    "\n",
    "train_time = time() - t0\n",
    "y_pred = reg.predict(x_test)\n",
    "\n",
    "df_pred3 = data.copy()\n",
    "df_pred3[\"y_pred\"] = y_pred\n",
    "\n",
    "ax = df_pred3.plot.scatter(\"x\", \"y\", figsize=(12, 5), s=15, label=\"y\")\n",
    "df_pred3.plot.scatter(\"x\", \"y_pred\", ax=ax, c=\"r\", s=15, label=\"y_pred\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Polynomial regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "x_train_poly = poly.fit_transform(x_train)\n",
    "x_test_poly = poly.transform(x_test)\n",
    "\n",
    "reg = None\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "t0 = time()\n",
    "\n",
    "reg.fit(x_train_poly, y_train[:, 0])\n",
    "\n",
    "print(\"Training Time:  \\t {:.3f} s\".format(time() - t0))\n",
    "\n",
    "\n",
    "train_time = time() - t0\n",
    "y_pred = reg.predict(x_test_poly)\n",
    "\n",
    "df_pred3 = data.copy()\n",
    "df_pred3[\"y_pred\"] = y_pred\n",
    "\n",
    "ax = df_pred3.plot.scatter(\"x\", \"y\", figsize=(12, 5), s=15, label=\"y\")\n",
    "df_pred3.plot.scatter(\"x\", \"y_pred\", ax=ax, c=\"r\", s=15, label=\"y_pred\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
