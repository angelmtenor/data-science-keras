{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Scandal: Indentifying Person of Interest\n",
    "\n",
    "**Identification of Enron employees who may have committed fraud**\n",
    "\n",
    "**Supervised Learning. Classification**\n",
    "\n",
    "Data: [Enron financial dataset from Udacity](https://github.com/udacity/ud120-projects/tree/master/final_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import helper\n",
    "import keras\n",
    "\n",
    "helper.info_gpu()\n",
    "# sns.set_palette(\"Reds\")\n",
    "helper.reproducible(seed=0)  # setup reproducible results from run to run using Keras\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/enron_financial_data.pkl\"\n",
    "target = [\"poi\"]\n",
    "\n",
    "df = pd.read_pickle(data_path)\n",
    "df = pd.DataFrame.from_dict(df, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.info_data(df, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Imbalanced target: the evaluation metric used in this problem is the Area Under the ROC Curve ** <br>\n",
    "**poi** =  person of interest (boolean) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete 'TOTAL' row (at the bottom)\n",
    "if \"TOTAL\" in df.index:\n",
    "    df.drop(\"TOTAL\", axis=\"index\", inplace=True)\n",
    "\n",
    "# convert dataframe values (objects) to numerical. There are no categorical features\n",
    "df = df.apply(pd.to_numeric, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-missing features, like 'loan_advances', are needed to obtain better models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove irrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"email_address\", axis=\"columns\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = list(df.select_dtypes(include=[np.number]))\n",
    "\n",
    "df = helper.classify_data(df, target, numerical=num)\n",
    "\n",
    "helper.get_types(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reeplace NaN values with the median\n",
    "df.fillna(df.median(), inplace=True)\n",
    "# helper.fill_simple(df, target, inplace=True) # same result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(percentiles=[0.5]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.show_numerical(df, kde=True, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target vs Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.show_target_vs_numerical(df, target, jitter=0.05, point_size=50, ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total stock value vs some features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot.scatter(x='salary', y='total_stock_value')\n",
    "# df.plot.scatter(x='long_term_incentive', y='total_stock_value')\n",
    "\n",
    "# sns.lmplot(x=\"salary\", y=\"total_stock_value\", hue='poi', data=df)\n",
    "# sns.lmplot(x=\"long_term_incentive\", y=\"total_stock_value\", hue='poi', data=df)\n",
    "\n",
    "g = sns.PairGrid(\n",
    "    df,\n",
    "    y_vars=[\"total_stock_value\"],\n",
    "    x_vars=[\"salary\", \"long_term_incentive\", \"from_this_person_to_poi\"],\n",
    "    hue=\"poi\",\n",
    "    size=4,\n",
    ")\n",
    "g.map(sns.regplot).add_legend()\n",
    "plt.ylim(ymin=0, ymax=0.5e8)\n",
    "\n",
    "# sns.pairplot(df, hue='poi', vars=['long_term_incentive', 'total_stock_value', 'from_poi_to_this_person'], kind='reg', size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The person of interest seems to have a higher stock vs salary and long-term incentive, especially when his stock value is high. There is no dependency between POI and the amount of emails from or to another person of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between numerical features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.correlation(df, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "droplist = []  # features to drop from the model\n",
    "\n",
    "# For the model 'data' instead of 'df'\n",
    "data = df.copy()\n",
    "data.drop(droplist, axis=\"columns\", inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale numerical features\n",
    "Shift and scale numerical variables to a standard normal distribution. The scaling factors are saved to be used for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, scale_param = helper.scale(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets\n",
    "Data leakage: Test set hidden when training the model, but seen when preprocessing the dataset\n",
    "\n",
    "No validation set (small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.4\n",
    "random_state = 9\n",
    "\n",
    "x_train, y_train, x_test, y_test = helper.simple_split(data, target, True, test_size, random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = helper.one_hot_output(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train size \\t X:{} \\t Y:{}\".format(x_train.shape, y_train.shape))\n",
    "print(\"test size  \\t X:{} \\t Y:{} \".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.dummy_clf(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network for Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight for imbalance target\n",
    "\n",
    "cw = helper.get_class_weight(y_train[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"models\", \"enron_scandal.h5\")\n",
    "\n",
    "model = None\n",
    "model = helper.build_nn_clf(x_train.shape[1], y_train.shape[1], dropout=0.3, summary=True)\n",
    "\n",
    "helper.train_nn(model, x_train, y_train, class_weight=cw, path=model_path)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_train = model.predict(x_train, verbose=0)\n",
    "print(\"\\nROC_AUC train:\\t{:.2f} \\n\".format(roc_auc_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset too small for train, validation, and test sets. More data is needed for a proper\n",
    "y_pred = model.predict(x_test, verbose=0)\n",
    "\n",
    "helper.binary_classification_scores(y_test[:, 1], y_pred[:, 1], return_dataframe=True, index=\"DNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with non-neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.ml_classification(x_train, y_train[:, 1], x_test, y_test[:, 1])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
